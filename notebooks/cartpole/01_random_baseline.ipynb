{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90ed25e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run `pip install \"gymnasium[classic-control]\"` for this example.\n",
    "import gymnasium as gym\n",
    "from pathlib import Path\n",
    "from gymnasium.wrappers import RecordVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1fa2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our training environment - a cart with a pole that needs balancing\n",
    "# env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\") #render_mode=\"human\", creates a pop up window showing it learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6701ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_dir = Path(\"../../documentation/cartpole/random-baseline/videos\")\n",
    "video_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "env = RecordVideo(\n",
    "    env,\n",
    "    video_folder=str(video_dir),\n",
    "    episode_trigger=lambda e: True,     # record first episode of this run\n",
    "    name_prefix=\"cartpole_random\"       # filename prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32d157e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(2)\n",
      "Observation space: Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n",
      "Starting observation: [ 0.0273956  -0.00611216  0.03585979  0.0197368 ]\n",
      "maxiumum number of steps per episode: 500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reset environment to start a new episode\n",
    "observation, info = env.reset(seed=42)\n",
    "# observation: what the agent can \"see\" - cart position, velocity, pole angle, etc.\n",
    "\n",
    "print(f\"Action space: {env.action_space}\") #discrete(2), can only go left or right\n",
    "print(f\"Observation space: {env.observation_space}\")  # Box(4D values), essentially all the agent can see\n",
    "print(f\"Starting observation: {observation}\")\n",
    "print(f\"maxiumum number of steps per episode: {env.spec.max_episode_steps}\")\n",
    "# [cart_position, cart_velocity, pole_angle, pole_angular_velocity]\n",
    "\n",
    "episode_over = False\n",
    "total_reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8f5f628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "Action taken: 0\n",
      "cart position: 0.02727336250245571\n",
      "cart velocity: -0.20172953605651855\n",
      "pole angle: 0.036254528909921646\n",
      "pole angular velocity: 0.32351475954055786\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 2:\n",
      "Action taken: 1\n",
      "cart position: 0.02323877066373825\n",
      "cart velocity: -0.007142078131437302\n",
      "pole angle: 0.04272482171654701\n",
      "pole angular velocity: 0.042481862008571625\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 3:\n",
      "Action taken: 1\n",
      "cart position: 0.023095929995179176\n",
      "cart velocity: 0.18734200298786163\n",
      "pole angle: 0.043574459850788116\n",
      "pole angular velocity: -0.23642075061798096\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 4:\n",
      "Action taken: 1\n",
      "cart position: 0.026842769235372543\n",
      "cart velocity: 0.38181519508361816\n",
      "pole angle: 0.03884604573249817\n",
      "pole angular velocity: -0.5150468349456787\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 5:\n",
      "Action taken: 1\n",
      "cart position: 0.03447907418012619\n",
      "cart velocity: 0.5763691663742065\n",
      "pole angle: 0.028545109555125237\n",
      "pole angular velocity: -0.7952397465705872\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 6:\n",
      "Action taken: 1\n",
      "cart position: 0.0460064560174942\n",
      "cart velocity: 0.7710879445075989\n",
      "pole angle: 0.012640314176678658\n",
      "pole angular velocity: -1.0788078308105469\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 7:\n",
      "Action taken: 0\n",
      "cart position: 0.061428215354681015\n",
      "cart velocity: 0.5758013725280762\n",
      "pole angle: -0.008935842663049698\n",
      "pole angular velocity: -0.7821852564811707\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 8:\n",
      "Action taken: 0\n",
      "cart position: 0.07294424623250961\n",
      "cart velocity: 0.3808034062385559\n",
      "pole angle: -0.024579547345638275\n",
      "pole angular velocity: -0.4923270046710968\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 9:\n",
      "Action taken: 0\n",
      "cart position: 0.08056031167507172\n",
      "cart velocity: 0.1860366016626358\n",
      "pole angle: -0.034426089376211166\n",
      "pole angular velocity: -0.2074907273054123\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 10:\n",
      "Action taken: 1\n",
      "cart position: 0.08428104221820831\n",
      "cart velocity: 0.3816334903240204\n",
      "pole angle: -0.038575902581214905\n",
      "pole angular velocity: -0.5108314752578735\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 11:\n",
      "Action taken: 0\n",
      "cart position: 0.09191371500492096\n",
      "cart velocity: 0.18707557022571564\n",
      "pole angle: -0.048792533576488495\n",
      "pole angular velocity: -0.23055022954940796\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 12:\n",
      "Action taken: 0\n",
      "cart position: 0.09565522521734238\n",
      "cart velocity: -0.007316422648727894\n",
      "pole angle: -0.05340353772044182\n",
      "pole angular velocity: 0.04635142534971237\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 13:\n",
      "Action taken: 0\n",
      "cart position: 0.09550889581441879\n",
      "cart velocity: -0.2016335427761078\n",
      "pole angle: -0.05247650668025017\n",
      "pole angular velocity: 0.32171839475631714\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 14:\n",
      "Action taken: 1\n",
      "cart position: 0.09147622436285019\n",
      "cart velocity: -0.005805103573948145\n",
      "pole angle: -0.04604214057326317\n",
      "pole angular velocity: 0.012959078885614872\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 15:\n",
      "Action taken: 0\n",
      "cart position: 0.09136012196540833\n",
      "cart velocity: -0.20023754239082336\n",
      "pole angle: -0.04578295722603798\n",
      "pole angular velocity: 0.2907670736312866\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 16:\n",
      "Action taken: 0\n",
      "cart position: 0.08735537528991699\n",
      "cart velocity: -0.3946777880191803\n",
      "pole angle: -0.0399676188826561\n",
      "pole angular velocity: 0.5686663389205933\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 17:\n",
      "Action taken: 1\n",
      "cart position: 0.07946182042360306\n",
      "cart velocity: -0.1990187168121338\n",
      "pole angle: -0.02859429083764553\n",
      "pole angular velocity: 0.26366475224494934\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 18:\n",
      "Action taken: 0\n",
      "cart position: 0.07548144459724426\n",
      "cart velocity: -0.3937211036682129\n",
      "pole angle: -0.023320995271205902\n",
      "pole angular velocity: 0.5471933484077454\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 19:\n",
      "Action taken: 1\n",
      "cart position: 0.06760702282190323\n",
      "cart velocity: -0.19827941060066223\n",
      "pole angle: -0.012377128936350346\n",
      "pole angular velocity: 0.24725477397441864\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 20:\n",
      "Action taken: 0\n",
      "cart position: 0.06364142894744873\n",
      "cart velocity: -0.3932224214076996\n",
      "pole angle: -0.007432033307850361\n",
      "pole angular velocity: 0.5360081195831299\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 21:\n",
      "Action taken: 1\n",
      "cart position: 0.05577698349952698\n",
      "cart velocity: -0.19799676537513733\n",
      "pole angle: 0.003288129111751914\n",
      "pole angular velocity: 0.2409927248954773\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 22:\n",
      "Action taken: 0\n",
      "cart position: 0.05181704834103584\n",
      "cart velocity: -0.3931655287742615\n",
      "pole angle: 0.008107983507215977\n",
      "pole angular velocity: 0.5347110033035278\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 23:\n",
      "Action taken: 0\n",
      "cart position: 0.04395373910665512\n",
      "cart velocity: -0.5884005427360535\n",
      "pole angle: 0.018802203238010406\n",
      "pole angular velocity: 0.8299376368522644\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 24:\n",
      "Action taken: 0\n",
      "cart position: 0.03218572586774826\n",
      "cart velocity: -0.7837744355201721\n",
      "pole angle: 0.035400956869125366\n",
      "pole angular velocity: 1.1284741163253784\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 25:\n",
      "Action taken: 1\n",
      "cart position: 0.016510238870978355\n",
      "cart velocity: -0.589133620262146\n",
      "pole angle: 0.05797043815255165\n",
      "pole angular velocity: 0.8471015691757202\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 26:\n",
      "Action taken: 0\n",
      "cart position: 0.004727566614747047\n",
      "cart velocity: -0.7849963903427124\n",
      "pole angle: 0.07491246610879898\n",
      "pole angular velocity: 1.1574360132217407\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 27:\n",
      "Action taken: 0\n",
      "cart position: -0.010972361080348492\n",
      "cart velocity: -0.9810105562210083\n",
      "pole angle: 0.09806118905544281\n",
      "pole angular velocity: 1.4726362228393555\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 28:\n",
      "Action taken: 1\n",
      "cart position: -0.030592571943998337\n",
      "cart velocity: -0.7872146964073181\n",
      "pole angle: 0.12751391530036926\n",
      "pole angular velocity: 1.2121227979660034\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 29:\n",
      "Action taken: 1\n",
      "cart position: -0.04633686691522598\n",
      "cart velocity: -0.5939481258392334\n",
      "pole angle: 0.1517563760280609\n",
      "pole angular velocity: 0.9619642496109009\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 30:\n",
      "Action taken: 1\n",
      "cart position: -0.058215830475091934\n",
      "cart velocity: -0.4011552631855011\n",
      "pole angle: 0.17099565267562866\n",
      "pole angular velocity: 0.7205438613891602\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 31:\n",
      "Action taken: 0\n",
      "cart position: -0.06623893231153488\n",
      "cart velocity: -0.5981783866882324\n",
      "pole angle: 0.18540653586387634\n",
      "pole angular velocity: 1.0617965459823608\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 32:\n",
      "Action taken: 0\n",
      "cart position: -0.0782025009393692\n",
      "cart velocity: -0.7952061295509338\n",
      "pole angle: 0.20664246380329132\n",
      "pole angular velocity: 1.4064706563949585\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 33:\n",
      "Action taken: 0\n",
      "cart position: -0.09410662204027176\n",
      "cart velocity: -0.9922052025794983\n",
      "pole angle: 0.23477187752723694\n",
      "pole angular velocity: 1.7560040950775146\n",
      "Reward: 1.0\n",
      "Terminated: True, Truncated: False\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "while not episode_over:\n",
    "    step += 1\n",
    "    # Choose an action: 0 = push cart left, 1 = push cart right\n",
    "    action = env.action_space.sample()  # Random action for now - real agents will be smarter!\n",
    "\n",
    "    # Take the action and see what happens\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # reward: +1 for each step the pole stays upright\n",
    "    # terminated: True if pole falls too far (agent failed)\n",
    "    # truncated: True if we hit the time limit (500 steps)\n",
    "\n",
    "    total_reward += reward\n",
    "    episode_over = terminated or truncated\n",
    "    print(f\"Step {step}:\")\n",
    "    print(f\"Action taken: {action}\")\n",
    "    \n",
    "    # print(f\"Observation: {observation}\") \n",
    "\n",
    "    labels = [\"cart position\", \"cart velocity\", \"pole angle\", \"pole angular velocity\"]\n",
    "    for label, observe in zip(labels,observation):\n",
    "        print(f\"{label}: {observe}\")\n",
    "\n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Terminated: {terminated}, Truncated: {truncated}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "884bcba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished! Total reward: 33.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Episode finished! Total reward: {total_reward}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc1062d",
   "metadata": {},
   "source": [
    "### writing to docs folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1542e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://realpython.com/python-pathlib/\n",
    "\n",
    "docs_path = Path(\"../../documentation/cartpole/random-baseline\") # ../ makes it so it writes to a directory one back from current one\n",
    "docs_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "graphs_dir  = docs_path / \"graphs\"\n",
    "graphs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "report_file = docs_path / \"random_baseline.md\"\n",
    "\n",
    "obs_explanation = \"\"\"\\\n",
    "**Observation vector (4 values):**\n",
    "1. **Cart Position (m)** — horizontal position on the track (≈ -4.8 to +4.8).\n",
    "2. **Cart Velocity (m/s)** — how fast the cart moves (unbounded float in practice).\n",
    "3. **Pole Angle (rad)** — tilt of the pole relative to vertical (≈ -0.4189 to +0.4189 rad ≈ ±24°).\n",
    "4. **Pole Angular Velocity (rad/s)** — how fast the pole is rotating (unbounded float in practice).\n",
    "\"\"\"\n",
    "\n",
    "failure_conditions = \"\"\"\\\n",
    "**Episode ends when (termination/truncation):**\n",
    "- **Pole tilt exceeds ±0.4189 rad (~±24°)** → `terminated = True`\n",
    "- **Cart position leaves track bounds (≈ ±4.8 m)** → `terminated = True`\n",
    "- **Time limit of 500 steps is reached** → `truncated = True`\n",
    "\"\"\"\n",
    "\n",
    "with open(report_file, \"w\")as f:\n",
    "    f.write(\"# SCRUM-15: Researching Cartpole test write\\n\\n\")\n",
    "    f.write(\"## Environment Details\\n\")\n",
    "    f.write(f\"- Action space: {env.action_space}\\n\")\n",
    "    f.write(f\"- Observation space: {env.observation_space}\\n\")\n",
    "    f.write(f\"- Maximum steps per episode: {env.spec.max_episode_steps}\\n\\n\")\n",
    "\n",
    "    f.write(\"## Observation Meaning\\n\")\n",
    "    f.write(obs_explanation + \"\\n\")\n",
    "\n",
    "    f.write(\"## Failure Conditions\\n\")\n",
    "    f.write(failure_conditions + \"\\n\")\n",
    "\n",
    "\n",
    "    f.write(\"## Example Run\\n\")\n",
    "    f.write(f\"- Starting observation: {observation.tolist()}\\n\")\n",
    "    f.write(f\"- Total reward: {total_reward}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
