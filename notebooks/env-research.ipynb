{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "90ed25e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run `pip install \"gymnasium[classic-control]\"` for this example.\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f1fa2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our training environment - a cart with a pole that needs balancing\n",
    "# env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "env = gym.make(\"CartPole-v1\") #render_mode=\"human\", creates a pop up window showing it learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "32d157e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(2)\n",
      "Observation space: Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n",
      "Starting observation: [ 0.0273956  -0.00611216  0.03585979  0.0197368 ]\n",
      "maxiumum number of steps per episode: 500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reset environment to start a new episode\n",
    "observation, info = env.reset(seed=42)\n",
    "# observation: what the agent can \"see\" - cart position, velocity, pole angle, etc.\n",
    "\n",
    "print(f\"Action space: {env.action_space}\") #discrete(2), can only go left or right\n",
    "print(f\"Observation space: {env.observation_space}\")  # Box(4D values), essentially all the agent can see\n",
    "print(f\"Starting observation: {observation}\")\n",
    "print(f\"maxiumum number of steps per episode: {env.spec.max_episode_steps}\")\n",
    "# [cart_position, cart_velocity, pole_angle, pole_angular_velocity]\n",
    "\n",
    "episode_over = False\n",
    "total_reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f8f5f628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "Action taken: 0\n",
      "cart position: 0.02727336250245571\n",
      "cart velocity: -0.20172953605651855\n",
      "pole angle: 0.036254528909921646\n",
      "pole angular velocity: 0.32351475954055786\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 2:\n",
      "Action taken: 1\n",
      "cart position: 0.02323877066373825\n",
      "cart velocity: -0.007142078131437302\n",
      "pole angle: 0.04272482171654701\n",
      "pole angular velocity: 0.042481862008571625\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 3:\n",
      "Action taken: 1\n",
      "cart position: 0.023095929995179176\n",
      "cart velocity: 0.18734200298786163\n",
      "pole angle: 0.043574459850788116\n",
      "pole angular velocity: -0.23642075061798096\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 4:\n",
      "Action taken: 1\n",
      "cart position: 0.026842769235372543\n",
      "cart velocity: 0.38181519508361816\n",
      "pole angle: 0.03884604573249817\n",
      "pole angular velocity: -0.5150468349456787\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 5:\n",
      "Action taken: 0\n",
      "cart position: 0.03447907418012619\n",
      "cart velocity: 0.18616832792758942\n",
      "pole angle: 0.028545109555125237\n",
      "pole angular velocity: -0.21038006246089935\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 6:\n",
      "Action taken: 1\n",
      "cart position: 0.0382024385035038\n",
      "cart velocity: 0.3808707594871521\n",
      "pole angle: 0.024337507784366608\n",
      "pole angular velocity: -0.4939236044883728\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 7:\n",
      "Action taken: 1\n",
      "cart position: 0.045819856226444244\n",
      "cart velocity: 0.5756411552429199\n",
      "pole angle: 0.0144590362906456\n",
      "pole angular velocity: -0.7788381576538086\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 8:\n",
      "Action taken: 0\n",
      "cart position: 0.05733267962932587\n",
      "cart velocity: 0.3803234100341797\n",
      "pole angle: -0.001117727137170732\n",
      "pole angular velocity: -0.48164135217666626\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 9:\n",
      "Action taken: 1\n",
      "cart position: 0.06493914872407913\n",
      "cart velocity: 0.5754611492156982\n",
      "pole angle: -0.010750554502010345\n",
      "pole angular velocity: -0.7746763825416565\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 10:\n",
      "Action taken: 1\n",
      "cart position: 0.07644836604595184\n",
      "cart velocity: 0.7707293033599854\n",
      "pole angle: -0.026244081556797028\n",
      "pole angular velocity: -1.0707223415374756\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 11:\n",
      "Action taken: 0\n",
      "cart position: 0.09186295419931412\n",
      "cart velocity: 0.5759640336036682\n",
      "pole angle: -0.0476585291326046\n",
      "pole angular velocity: -0.7863898277282715\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 12:\n",
      "Action taken: 1\n",
      "cart position: 0.10338223725557327\n",
      "cart velocity: 0.7717071771621704\n",
      "pole angle: -0.06338632106781006\n",
      "pole angular velocity: -1.0936775207519531\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 13:\n",
      "Action taken: 1\n",
      "cart position: 0.11881637573242188\n",
      "cart velocity: 0.9676043391227722\n",
      "pole angle: -0.08525987714529037\n",
      "pole angular velocity: -1.4055562019348145\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 14:\n",
      "Action taken: 0\n",
      "cart position: 0.13816846907138824\n",
      "cart velocity: 0.7736380100250244\n",
      "pole angle: -0.11337099969387054\n",
      "pole angular velocity: -1.1406996250152588\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 15:\n",
      "Action taken: 1\n",
      "cart position: 0.1536412239074707\n",
      "cart velocity: 0.9700444340705872\n",
      "pole angle: -0.13618499040603638\n",
      "pole angular velocity: -1.4666776657104492\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 16:\n",
      "Action taken: 1\n",
      "cart position: 0.17304211854934692\n",
      "cart velocity: 1.1665455102920532\n",
      "pole angle: -0.16551853716373444\n",
      "pole angular velocity: -1.7986149787902832\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 17:\n",
      "Action taken: 1\n",
      "cart position: 0.19637301564216614\n",
      "cart velocity: 1.3630876541137695\n",
      "pole angle: -0.2014908492565155\n",
      "pole angular velocity: -2.1378395557403564\n",
      "Reward: 1.0\n",
      "Terminated: False, Truncated: False\n",
      "--------------------------------------------------\n",
      "Step 18:\n",
      "Action taken: 0\n",
      "cart position: 0.2236347794532776\n",
      "cart velocity: 1.17044997215271\n",
      "pole angle: -0.24424763023853302\n",
      "pole angular velocity: -1.9135671854019165\n",
      "Reward: 1.0\n",
      "Terminated: True, Truncated: False\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "while not episode_over:\n",
    "    step += 1\n",
    "    # Choose an action: 0 = push cart left, 1 = push cart right\n",
    "    action = env.action_space.sample()  # Random action for now - real agents will be smarter!\n",
    "\n",
    "    # Take the action and see what happens\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # reward: +1 for each step the pole stays upright\n",
    "    # terminated: True if pole falls too far (agent failed)\n",
    "    # truncated: True if we hit the time limit (500 steps)\n",
    "\n",
    "    total_reward += reward\n",
    "    episode_over = terminated or truncated\n",
    "    print(f\"Step {step}:\")\n",
    "    print(f\"Action taken: {action}\")\n",
    "    \n",
    "    # print(f\"Observation: {observation}\") \n",
    "\n",
    "    labels = [\"cart position\", \"cart velocity\", \"pole angle\", \"pole angular velocity\"]\n",
    "    for label, observe in zip(labels,observation):\n",
    "        print(f\"{label}: {observe}\")\n",
    "\n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Terminated: {terminated}, Truncated: {truncated}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "884bcba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished! Total reward: 18.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Episode finished! Total reward: {total_reward}\")\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
